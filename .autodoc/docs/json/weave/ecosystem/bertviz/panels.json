{
  "fileName": "panels.py",
  "filePath": "weave/ecosystem/bertviz/panels.py",
  "url": "https://github.com/wandb/weave/weave/ecosystem/bertviz/panels.py",
  "summary": "The `weave` project is a Python library for building interactive visualizations of data pipelines. This file, located in the `weave` module, provides functionality for visualizing attention matrices in BERT models using the `bertviz` library.\n\nThe `head_view` function takes a `huggingface.ModelOutputAttention` object as input and returns an HTML string that can be used to visualize the attention matrix for a single head in the BERT model. The function first extracts the necessary information from the input object, including the encoded input tokens, the BERT model, and the attention matrix. It then calls the `bertviz.head_view` function with this information to generate the HTML string. Finally, the HTML string is wrapped in a `weave.ops.Html` object and returned.\n\nThe `BertvizHeadView` class is a `weave.Panel` subclass that provides a UI component for visualizing the attention matrix for a single head. The class specifies that its input node should be a `huggingface.ModelOutputAttention` object. The `render` method of the class lazily calls the `head_view` function with the input node and returns a `weave.panels.PanelHtml` object containing the resulting HTML string.\n\nThe `model_view` function is similar to `head_view`, but instead of visualizing a single head, it visualizes the full matrix of attention heads as rows and layers as columns for each attention map. The `BertvizModelView` class is similar to `BertvizHeadView`, but provides a UI component for visualizing the full attention matrix. The `model_view_panel_render` method of the class lazily calls the `model_view` function with the input node and returns a `weave.panels.PanelHtml` object containing the resulting HTML string.\n\nOverall, this file provides a convenient way to visualize the attention matrices in BERT models using the `bertviz` library within the larger `weave` project. Here is an example of how this code might be used:\n\n```python\nimport transformers\nfrom weave import Weave\nfrom weave.contrib.huggingface import HuggingFaceModelOutputAttention\n\nmodel = transformers.BertModel.from_pretrained('bert-base-uncased')\ntokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n\ninputs = tokenizer.encode_plus('Hello, world!', return_tensors='pt')\noutputs = model(**inputs)\n\nattention = HuggingFaceModelOutputAttention(outputs)\n\nhead_view_panel = BertvizHeadView(input_node=attention).render()\nmodel_view_panel = BertvizModelView(input_node=attention).model_view_panel_render()\n\nweave = Weave([head_view_panel, model_view_panel])\nweave.show()\n```",
  "questions": "1. What is the purpose of the `weave` module in this code?\n- The `weave` module is used to define operations and types for creating UI panels that visualize attention maps in a BERT model.\n\n2. What is the difference between the `head_view` and `model_view` functions?\n- `head_view` visualizes the attention heads for a single layer of a BERT model, while `model_view` visualizes the attention heads for all layers of the model.\n\n3. What is the purpose of the `BertvizHeadView` and `BertvizModelView` classes?\n- These classes define UI panels that use the `head_view` and `model_view` functions to visualize attention maps for a BERT model. They specify the input type for the panel and define a `render` method that returns an HTML panel."
}